name: Live Tests

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  workflow_dispatch:

permissions:
  contents: read

jobs:
  live-test:
    runs-on: ubuntu-latest
    
    services:
      ollama:
        image: ollama/ollama:latest
        ports:
          - 11434:11434
        options: >-
          --health-cmd "curl -f http://localhost:11434/api/tags || exit 1"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        
    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y libmagic1 curl
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r requirements-dev.txt
        pip install requests
        
    - name: Wait for Ollama to be ready
      run: |
        echo "Waiting for Ollama service..."
        for i in {1..30}; do
          if curl -f http://localhost:11434/api/tags; then
            echo "Ollama is ready!"
            break
          fi
          echo "Waiting... ($i/30)"
          sleep 2
        done
        
    - name: Pull Ollama model
      run: |
        echo "Pulling llama2 model..."
        curl -X POST http://localhost:11434/api/pull -d '{"name": "llama2"}' &
        PULL_PID=$!
        
        # Wait for pull to complete (with timeout)
        for i in {1..300}; do
          if curl -s http://localhost:11434/api/tags | grep -q "llama2"; then
            echo "Model pulled successfully!"
            break
          fi
          if [ $i -eq 300 ]; then
            echo "Timeout waiting for model pull"
            exit 1
          fi
          echo "Waiting for model pull... ($i/300)"
          sleep 2
        done
        
    - name: Verify model availability
      run: |
        echo "Checking available models..."
        curl http://localhost:11434/api/tags
        
    - name: Run live tests
      env:
        OLLAMA_BASE_URL: http://localhost:11434
        OLLAMA_MODEL: llama2
      run: |
        pytest tests/test_live.py -v --tb=short
        
    - name: Run live tests with coverage
      if: success() || failure()
      env:
        OLLAMA_BASE_URL: http://localhost:11434
        OLLAMA_MODEL: llama2
      run: |
        pytest tests/test_live.py --cov=ai_file_organizer --cov-report=xml --cov-report=term
        
    - name: Upload coverage
      if: success()
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        flags: livetests
        name: codecov-live-tests
        fail_ci_if_error: false
