name: Live Tests

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  workflow_dispatch:

permissions:
  contents: read

jobs:
  live-test:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        
    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y libmagic1 curl docker-compose
        
    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r requirements-dev.txt
        pip install pyyaml
        
    - name: Start Ollama with docker-compose
      run: |
        docker-compose up -d ollama
        
    - name: Wait for Ollama to be ready
      run: |
        echo "Waiting for Ollama service..."
        for i in {1..60}; do
          if curl -f http://localhost:11434/api/tags 2>/dev/null; then
            echo "Ollama is ready!"
            break
          fi
          echo "Waiting... ($i/60)"
          sleep 2
        done
        
    - name: Pull Ollama model
      run: |
        echo "Pulling llama2 model..."
        curl -X POST http://localhost:11434/api/pull -d '{"name": "llama2"}' &
        
        # Wait for pull to complete (with timeout)
        for i in {1..300}; do
          if curl -s http://localhost:11434/api/tags | grep -q "llama2"; then
            echo "Model pulled successfully!"
            break
          fi
          if [ $i -eq 300 ]; then
            echo "Timeout waiting for model pull"
            exit 1
          fi
          echo "Waiting for model pull... ($i/300)"
          sleep 2
        done
        
    - name: Verify model availability
      run: |
        echo "Checking available models..."
        curl http://localhost:11434/api/tags
        
    - name: Run live tests
      env:
        OLLAMA_BASE_URL: http://localhost:11434
        OLLAMA_MODEL: llama2
      run: |
        pytest tests/test_live.py -m live -v --tb=short
        
    - name: Run live tests with coverage
      if: success() || failure()
      env:
        OLLAMA_BASE_URL: http://localhost:11434
        OLLAMA_MODEL: llama2
      run: |
        pytest tests/test_live.py -m live --cov=src/ai_file_organizer --cov-report=xml --cov-report=term
        
    - name: Show docker-compose logs on failure
      if: failure()
      run: |
        docker-compose logs
        
    - name: Cleanup
      if: always()
      run: |
        docker-compose down -v
        
    - name: Upload coverage
      if: success()
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        flags: livetests
        name: codecov-live-tests
        fail_ci_if_error: false
