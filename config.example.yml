# AI/LLM Configuration
ai:
  provider: openai  # openai, azure, google, or local
  model: gpt-3.5-turbo
  temperature: 0.3
  api_key: YOUR_API_KEY_HERE
  
  # For Azure
  # azure_endpoint: https://your-resource.openai.azure.com/
  # deployment_name: your-deployment
  
  # For Google Gemini
  # model: gemini-pro
  # api_key: YOUR_GOOGLE_API_KEY
  
  # For Local LLM
  # base_url: http://localhost:8000/v1

# Category labels
# Simple list format (flat labels):
# labels:
#   - Documents
#   - Images
#   - Videos
#   - Audio
#   - Archives
#   - Code
#   - Other

# Hierarchical format (labels with sub-labels):
# Use a dictionary where keys are parent labels and values are lists of sub-labels
# Labels without sub-labels can be included as simple strings
labels:
  Documents:
    - Work
    - Personal
    - Financial
  Images:
    - Photos
    - Screenshots
    - Designs
  Videos: []  # No sub-labels for Videos
  Audio: []   # No sub-labels for Audio
  Archives: []
  Code:
    - Python
    - JavaScript
    - Other Code
  Other: []

# Folder paths (for Docker)
input_folder: /input
output_folder: /output

# Continuous mode settings
continuous: false  # Set to true to run in continuous mode
interval: 60  # Interval in seconds between scans (only used if continuous=true)
